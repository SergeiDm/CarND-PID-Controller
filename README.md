# CarND-PID-Controller
## Project Description
The project consists of learning network to map images taken from a front-facing camera with steering angles. According to NVIDEA [«End to End Learning for Self-Driving Cars»](https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf), this approach for self-driving cars may lead to better performance in comparison explicit decomposition of the self-driving problem.

## Project files
The project includes the following folder/files:
- model.py – the script to create and train the model.
- drive.py – for driving the car in autonomous mode.
- model.h5 – the model weights.
- model.json – the model architecture.
- illustrations - the folder with pictures 'for README.md'.

Result video of this project:

<a href="https://www.youtube.com/watch?v=wug6ksRY5BQ" target="_blank"><img src="http://img.youtube.com/vi/wug6ksRY5BQ/0.jpg" 
alt="IMAGE ALT TEXT HERE" width="240" height="180" border="10" /></a>

For testing autonomous driving the following code should be executed:

## Project Data
Input data is a set of RGB images 160 (height) x 320 (width) pixels, generated by the driving simulator in training mode. 

Examples:

![Image examples](https://github.com/SergeiDm/CarND-Behavioral-Cloning/blob/master/illustrations/image_examples.jpg)

The total number of images used in this project is 14 821. ~30% of them is recovery data.

Output data is steering angles in range [-1, 1].
